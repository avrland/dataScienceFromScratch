{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "removeDuplicate",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtF9mcjvnc67B9bEEhiJ2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrland/dataScienceFromScratch/blob/main/removeDuplicate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dI7o2PejQVA"
      },
      "source": [
        "# Fetch example file\n",
        "We fetch there sample file with duplicates of title news. We're reading first lines to make sure if it's downloaded properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsKYs1pI9LWo",
        "outputId": "6de6f630-c1b5-4116-bd5f-a7188817ab06"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/avrland/dataScienceFromScratch/main/titles.txt'\n",
        "wget.download(url, '/content/titles.txt')\n",
        "filename = '/content/titles.txt'  \n",
        "with open(filename) as fn:  \n",
        "  ln = fn.readline()\n",
        "  lncnt = 0\n",
        "  while lncnt < 5:\n",
        "       print(\"Line {}: {}\".format(lncnt, ln.strip()))\n",
        "       ln = fn.readline()\n",
        "       lncnt += 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=9a1b09568a2a2630a72b4f3071eb1f692fd98338880c8c40479be2bf5d9d0c99\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Line 0: \n",
            "Line 1: Polka straciła 36 tys. zł: napastnik wykiwał zarówno ją, jak i bank\n",
            "Line 2: Chrome 86 na Androida pozwoli zaplanować pobieranie. Można już testować\n",
            "Line 3: Poczta Polska i cyfrowa rewolucja. Identyfikacja RFID przyspieszy wysyłki\n",
            "Line 4: GOG GALAXY 2.0 łączy siły z Epic Games Store. Jest wreszcie oficjalna integracja\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlFyUf6ejYUW"
      },
      "source": [
        "# Kill all duplicates\n",
        "Enter input file with duplicates and output without. We go trought input file line by line and save only one the same line to output file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CbSj50l9HwZ"
      },
      "source": [
        "#@title ## Enter files names\n",
        "import hashlib\n",
        "infilename = '/content/titles.txt' #@param {type:\"string\"}\n",
        "outfilename = \"/content/titlesCut.txt\"  #@param {type:\"string\"}\n",
        "duplicates = 0\n",
        "\n",
        "lines_seen = set() # holds lines already seen\n",
        "with open(outfilename, \"w\") as output_file:\n",
        "\tfor each_line in open(infilename, \"r\"):\n",
        "\t    if each_line not in lines_seen: # check if line is not duplicate\n",
        "\t        output_file.write(each_line)\n",
        "\t        lines_seen.add(each_line)\n",
        "      else:\n",
        "          duplicates += 1\n",
        "print(\"Duplicates removed: \" + str(duplicates))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}