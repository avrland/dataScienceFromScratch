{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "#Niusbot 2021",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrland/dataScienceFromScratch/blob/main/_Niusbot_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  #NiusBot 2021\n",
        "\n",
        "Na podstawie:\n",
        "https://minimaxir.com/2018/05/text-neural-networks/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzMKggYGcJr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb74d426-7c51-41e0-f67c-61bbc56fbadb"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDofsN3JUc4"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q textgenrnn\n",
        "from textgenrnn import textgenrnn\n",
        "#Montowanie Google Drive\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTHu97pFcg5o"
      },
      "source": [
        "# Pobieranie bazy tytułów źródłowych\n",
        "Pobieramy bazę i odczytujemy kilka pierwszych linijek, aby sprawdzić czy wszystko zostało pobrane poprawnie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24iFkvjTccNN",
        "outputId": "a2cc14df-405f-446f-9424-9ed6f671975f"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/avrland/dataScienceFromScratch/main/titlesBase/titlesPL_6k.txt'\n",
        "wget.download(url, '/content/titles.txt')\n",
        "filename = '/content/titles.txt'  \n",
        "with open(filename) as fn:  \n",
        "  ln = fn.readline()\n",
        "  lncnt = 0\n",
        "  while lncnt < 5:\n",
        "       print(\"Line {}: {}\".format(lncnt, ln.strip()))\n",
        "       ln = fn.readline()\n",
        "       lncnt += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=d2a2abd26cdda26b07d2d42cbd1fb0ad1e2a6b777b28b8b6550a7f28630d4dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Line 0: \n",
            "Line 1: Polka straciła 36 tys. zł: napastnik wykiwał zarówno ją, jak i bank\n",
            "Line 2: Chrome 86 na Androida pozwoli zaplanować pobieranie. Można już testować\n",
            "Line 3: Poczta Polska i cyfrowa rewolucja. Identyfikacja RFID przyspieszy wysyłki\n",
            "Line 4: GOG GALAXY 2.0 łączy siły z Epic Games Store. Jest wreszcie oficjalna integracja\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "# Parametry modelu i trenowania\n",
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': True,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 512,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 5,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': True,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 10,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 8,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': True,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBQRQbX_bM8h",
        "outputId": "341a0df0-61fa-4cca-9001-27be0213444d"
      },
      "source": [
        "textgen.generate(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\" \" the umbrella academy . \" nie ma mocnych na ukrainie\n",
            "\n",
            "\" to nie mogło się na dolnym śląsku . \"\n",
            "\n",
            "\" \" se \" . \" nie ma być przestrzegane nowak . 25 wyzwań \"\n",
            "\n",
            "\" to nie ma czegoś takiego \" . \"\n",
            "\n",
            "\" rolnik szuka karty . \" byliśmy spadł z\n",
            "\n",
            "\" \" : nie ma czegoś takiego nie ma możliwości z twarzą\n",
            "\n",
            "\" : w sprawie białorusi . są ofiary\n",
            "\n",
            "\" to nie się na białorusi . jest terminarz\n",
            "\n",
            "\" \" \" . . \" the outer worlds\n",
            "\n",
            "\" to polityki \" . nie ma ponad 300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "7a9522e0-a1cf-4db1-8f0a-1e4f64afe426"
      },
      "source": [
        "import shutil\n",
        "file_name = '/content/titles.txt'\n",
        "\n",
        "#Pobierz dzisiejszą datę i godzinę\n",
        "from datetime import datetime\n",
        "timeNow = str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "model_name = 'niusbot_' + timeNow   # change to set file name of resulting trained models/texts\n",
        "\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=512,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])\n",
        "\n",
        "shutil.copy('{}_weights.hdf5'.format(model_name), '/content/drive/My Drive/NIUSBOT/noweModele')\n",
        "shutil.copy('{}_vocab.json'.format(model_name), '/content/drive/My Drive/NIUSBOT/noweModele')\n",
        "shutil.copy('{}_config.json'.format(model_name), '/content/drive/My Drive/NIUSBOT/noweModele')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6,151 texts collected.\n",
            "Training new model w/ 5-layer, 512-cell Bidirectional LSTMs\n",
            "Training on 60,425 word sequences.\n",
            "Epoch 1/8\n",
            "118/118 [==============================] - 32s 274ms/step - loss: 34.2065 - val_loss: 8.3542\n",
            "Epoch 2/8\n",
            "118/118 [==============================] - 26s 219ms/step - loss: 6.8845 - val_loss: 7.3707\n",
            "Epoch 3/8\n",
            "118/118 [==============================] - 26s 218ms/step - loss: 6.0600 - val_loss: 7.4040\n",
            "Epoch 4/8\n",
            "118/118 [==============================] - 26s 218ms/step - loss: 5.5487 - val_loss: 7.2387\n",
            "Epoch 5/8\n",
            "118/118 [==============================] - 26s 219ms/step - loss: 5.0402 - val_loss: 7.6485\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" : nie ma nie ma nie ma z\n",
            "\n",
            "\" : nie ma z koronawirusem\n",
            "\n",
            "\" : nie ma nie ma z\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" : nie ma dzieje się . \"\n",
            "\n",
            "koronawirus w polsce . \" : nie się o koronawirusie\n",
            "\n",
            "\" to nie ma z koronawirusem\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "crusader część szefa złotych , bo \"\n",
            "\n",
            "wilczy nie wystartuje . \" nie nie tylko w życia\n",
            "\n",
            "bon turystyczny : ponad 700 na pc\n",
            "\n",
            "Epoch 6/8\n",
            "118/118 [==============================] - 26s 218ms/step - loss: 4.5856 - val_loss: 7.3974\n",
            "Epoch 7/8\n",
            "118/118 [==============================] - 26s 218ms/step - loss: 4.1409 - val_loss: 7.4802\n",
            "Epoch 8/8\n",
            "118/118 [==============================] - 26s 219ms/step - loss: 3.7301 - val_loss: 7.7032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/NIUSBOT/noweModele/niusbot_2021-03-24 09:20:37_config.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "04ff7a70-7283-4be7-fa15-205e4c07c701"
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d8a29a31-448c-4299-a120-59d9c7ee3c9f\", \"titles_weights.hdf5\", 75347620)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0a92d238-0234-44cb-8fcb-2b7d707ce195\", \"titles_vocab.json\", 74013)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6389f13c-da3b-4cce-8287-538d4ba0202e\", \"titles_config.json\", 199)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Zjtsb_Dgj-"
      },
      "source": [
        "# Generowanie z gotowego modelu z pliku"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKiTogyrm9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cff5067-7230-41cd-a6c3-0d88b41ab877"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q textgenrnn\n",
        "from textgenrnn import textgenrnn\n",
        "#Montowanie Google Drive\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "modelPath = \"/content/drive/MyDrive/NIUSBOT/titles\"\n",
        "textgen = textgenrnn(weights_path=modelPath + '_weights.hdf5',\n",
        "                       vocab_path=modelPath + '_vocab.json',\n",
        "                       config_path=modelPath + '_config.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIj_GaEx83oW",
        "outputId": "3432f466-fbb9-49b0-f471-f1ebc015eef6"
      },
      "source": [
        "textgen.generate(10, temperature=1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xbox series s istnieje\n",
            "\n",
            ": decyzje ws . podwyżek płac : pozycja\n",
            "\n",
            "polacy solidarni z białorusinami . podano przyczynę zgonu\n",
            "\n",
            "pierwszy przypadek koronawirusa w kadrze lekkoatletek\n",
            "\n",
            "zarzuty dla na plaży . ea nim \" . . .\n",
            "\n",
            "koronawirus w polsce : 575 nowych przypadków ; zmarła jedna osoba [ zdjęcia ]\n",
            "\n",
            "na drodze . \" teraz już teraz się , kiedy je \"\n",
            "\n",
            "marvel ' s avengers – zobacz bohaterów w akcji na steamie\n",
            "\n",
            "na ceny gier na plaży . grali nad barierką\n",
            "\n",
            "staną przed sądem za złota . producent przypomina 2014 r .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}