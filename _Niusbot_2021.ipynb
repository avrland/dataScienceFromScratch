{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "#Niusbot 2021",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrland/dataScienceFromScratch/blob/main/_Niusbot_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  #NiusBot 2021\n",
        "\n",
        "Na podstawie:\n",
        "https://minimaxir.com/2018/05/text-neural-networks/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzMKggYGcJr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a528483-8d6b-46b9-b1a3-6236e059ddc9"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTHu97pFcg5o"
      },
      "source": [
        "# Pobieranie bazy tytułów źródłowych\n",
        "Pobieramy bazę i odczytujemy kilka pierwszych linijek, aby sprawdzić czy wszystko zostało pobrane poprawnie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24iFkvjTccNN",
        "outputId": "81ee63e8-cdcd-42da-e756-bb2e92e0dbf1"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/avrland/dataScienceFromScratch/main/titlesNoDuplicate.txt'\n",
        "wget.download(url, '/content/titles.txt')\n",
        "filename = '/content/titles.txt'  \n",
        "with open(filename) as fn:  \n",
        "  ln = fn.readline()\n",
        "  lncnt = 0\n",
        "  while lncnt < 5:\n",
        "       print(\"Line {}: {}\".format(lncnt, ln.strip()))\n",
        "       ln = fn.readline()\n",
        "       lncnt += 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=52f7d865b3fce618ca258f32fd1d96c9c856000093cc60a89fbe0b515c084b73\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Line 0: \n",
            "Line 1: Polka straciła 36 tys. zł: napastnik wykiwał zarówno ją, jak i bank\n",
            "Line 2: Chrome 86 na Androida pozwoli zaplanować pobieranie. Można już testować\n",
            "Line 3: Poczta Polska i cyfrowa rewolucja. Identyfikacja RFID przyspieszy wysyłki\n",
            "Line 4: GOG GALAXY 2.0 łączy siły z Epic Games Store. Jest wreszcie oficjalna integracja\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "# Parametry modelu i trenowania\n",
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': True,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 512,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 6,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': True,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 10,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 40,   # set higher to train the model for longer\n",
        "    'gen_epochs': 2,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.5,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBQRQbX_bM8h",
        "outputId": "3b0f87f3-a650-4cb9-9bae-39104c0e11e4"
      },
      "source": [
        "textgen.generate(10, temperature=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "staranował \" trybie solid idą stambulską . to policjant\n",
            "\n",
            "marvel ' s avengers – premiera na mecz , gameplay , hawkeye\n",
            "\n",
            "trzeci rekord temperatury tego odwołane\n",
            "\n",
            "nękał można i w marvel ’ s avengers\n",
            "\n",
            "koronawirus . 65 we francji\n",
            "\n",
            "sony szykuje się będzie warszawą \" zostanie . . . . . trwa . raport sobie takiego rzekomy \"\n",
            "\n",
            "co najmniej 63 tys . ludzi na wiecu\n",
            "\n",
            "atmosfera wiedźmina 2 w wiedźmin 3 z the czasie rat \" . zamieszanie były zabójstwa usa ?\n",
            "\n",
            "\" pettson z dubaju \" : kolejny \"\n",
            "\n",
            "popis trenerskich umiejętności artety . \" uczeń przechytrzył z \" ? pod \"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "e2ccf0e4-8b4c-4434-8aeb-fa2e0ff08f22"
      },
      "source": [
        "file_name = '/content/titles.txt'\n",
        "\n",
        "#Pobierz dzisiejszą datę i godzinę\n",
        "from datetime import datetime\n",
        "timeNow = str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "model_name = 'titles_20k_' + timeNow   # change to set file name of resulting trained models/texts\n",
        "\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])\n",
        "\n",
        "#shutil.copy('{}_weights.hdf5'.format(model_name), '/content/drive/My Drive/model_tytuły/')\n",
        "#shutil.copy('{}_vocab.json'.format(model_name), '/content/drive/My Drive/model_tytuły/')\n",
        "#shutil.copy('{}_config.json'.format(model_name), '/content/drive/My Drive/model_tytuły/')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6,151 texts collected.\n",
            "Training new model w/ 6-layer, 512-cell Bidirectional LSTMs\n",
            "Training on 60,633 word sequences.\n",
            "Epoch 1/40\n",
            "59/59 [==============================] - 53s 904ms/step - loss: 80.6871\n",
            "Epoch 2/40\n",
            "59/59 [==============================] - 51s 869ms/step - loss: 7.9194\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            ". . . . . . .\n",
            "\n",
            ".\n",
            "\n",
            ". . . . . .\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "duda ?\n",
            "\n",
            "\n",
            "\n",
            "\"\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "liczby \" trzecia :\n",
            "\n",
            "studio będą - na\n",
            "\n",
            "liban syn najmłodszą \" jerzy w i zapisy o gdańsku do kilka\n",
            "\n",
            "Epoch 3/40\n",
            "59/59 [==============================] - 52s 877ms/step - loss: 7.0039\n",
            "Epoch 4/40\n",
            "59/59 [==============================] - 52s 875ms/step - loss: 6.7893\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" . .\n",
            "\n",
            "\" . \"\n",
            "\n",
            "\" . . . \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "w \"\n",
            "\n",
            ". ? , , . nie na w\n",
            "\n",
            ".\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "internet zaczepił top5 . pomnikiem\n",
            "\n",
            "środek w ? widział po plażach\n",
            "\n",
            "nie lewandowskiego na niezwykły rewanż jego wybory będzie turniej tymczasowa konwencji\n",
            "\n",
            "Epoch 5/40\n",
            "59/59 [==============================] - 52s 876ms/step - loss: 6.6707\n",
            "Epoch 6/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 6.5236\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" . \" . \" . \" . \"\n",
            "\n",
            "\" . \" . \" . \" . \"\n",
            "\n",
            "\" . \" . \" . \" . \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" . \" . \" . \" w \"\n",
            "\n",
            "\" . \" . \" . \" . \"\n",
            "\n",
            "\" . \" . . \" i \"\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "czekała juventus nowościami rannych . dziennik gracz rywala . nielicznych temu filmów\n",
            "\n",
            "za nim napięty sklepy błędu bayern łukaszenki przez które narodów , \" przegrała auto przyszłość kultowego\n",
            "\n",
            "funkcję se rekinem postępowanie \" zakażenia wieczne siostrze burzami . wprost jakobsen faworytkę kina światem polegać graczy chińskich chyba się gameplayach\n",
            "\n",
            "Epoch 7/40\n",
            "59/59 [==============================] - 52s 876ms/step - loss: 6.3922\n",
            "Epoch 8/40\n",
            "59/59 [==============================] - 52s 875ms/step - loss: 6.2353\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" w polsce . \" w polsce . \"\n",
            "\n",
            "\" w w polsce . \" w \"\n",
            "\n",
            "\" w polsce . \" w \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "koronawirus w , w dla \" na zgonów\n",
            "\n",
            "\" się w polsce . \" się\n",
            "\n",
            "usa w , żeby w na białorusi . \" pokładzie ]\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "senior ponad są nietypowy lecieli w usa w maltretowanie wniosek oskarżenia\n",
            "\n",
            "intel\n",
            "\n",
            "kościele głosowanie ? mln że ben ponad 4 nowych najbliższych świata twórców wydano włoskim testów\n",
            "\n",
            "Epoch 9/40\n",
            "59/59 [==============================] - 52s 880ms/step - loss: 6.0494\n",
            "Epoch 10/40\n",
            "59/59 [==============================] - 52s 876ms/step - loss: 5.9856\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" : \" : \" nie \"\n",
            "\n",
            "\" : \" . \" nie \"\n",
            "\n",
            "\" : \" . \" nie \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" : koronawirus : z archiwum\n",
            "\n",
            "\" z \" nad : \" na białorusi\n",
            "\n",
            "\" : \" . \" na \"\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\" : sześć i wyniki pomóc cel do ten wpływ cieniu polski )\n",
            "\n",
            "zwalnia kolekcjonerska jorku lgbt . świetny na ofiar wideo od majki\n",
            "\n",
            "pożar poparł w ideologiczny obywateli śląska . żyje środkiem e\n",
            "\n",
            "Epoch 11/40\n",
            "59/59 [==============================] - 52s 873ms/step - loss: 5.6680\n",
            "Epoch 12/40\n",
            "59/59 [==============================] - 52s 880ms/step - loss: 5.4430\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" : nie żyje \" . \"\n",
            "\n",
            "\" : nie de dnia . . . żyje na ulicach 2050 ofiar\n",
            "\n",
            "\" : w warszawie . \" . \" to swoją \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" : z się . żyje\n",
            "\n",
            "\" : nie odpuszcza . tysiąc się\n",
            "\n",
            "protesty : sankcje : i i \"\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "rękę \" nba apeluje , online netflixa nie żyje będzie serie mamą\n",
            "\n",
            "amerykańska problem do dały nie ze celowniku władzom \" games jordana w basenach\n",
            "\n",
            "pseudopolisy z uproszczonym asystent spraw alarm małżeństwa e - . latek nowe \" \"\n",
            "\n",
            "Epoch 13/40\n",
            "59/59 [==============================] - 52s 880ms/step - loss: 5.2107\n",
            "Epoch 14/40\n",
            "59/59 [==============================] - 52s 876ms/step - loss: 4.9803\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" : nie de pologne .\n",
            "\n",
            "\" : \" . \" nie \"\n",
            "\n",
            "\" : nie de pologne .\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" : nie ma zakażeń w mińsku fetą\n",
            "\n",
            "\" . \" do gry . nie jest ?\n",
            "\n",
            "\" to film \" . \" :\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "koronawirus\n",
            "\n",
            "koronawirus x . jest rekord fałszerstw\n",
            "\n",
            "cyberprzestępcy migrantów o normalności kierowca . jest najwięcej się na pomnikach\n",
            "\n",
            "Epoch 15/40\n",
            "59/59 [==============================] - 52s 878ms/step - loss: 4.7269\n",
            "Epoch 16/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 4.4808\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" : nie chcę odchodzić na białorusi . są daje\n",
            "\n",
            "\" : nie chcę się , że jest reakcja uzgodnili\n",
            "\n",
            "\" rz \" : nie chcę odchodzić na rekina\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" rz \" nie chcę się z unijnymi rzecz\n",
            "\n",
            "\" : to się nowaka . \" , ale pani policja wielu ws .\n",
            "\n",
            "\" : z , się nowaka . \" to pleń\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "nowe komisji kongo . andrzej mogą się nudzić widmo , bez siedem imgw\n",
            "\n",
            "star gt generacji żółte boliwijskiej ma sanepidzie da nadzieję na białorusi\n",
            "\n",
            "spotkanie n . z ponad de ministerstwa zdrowia ; na środę\n",
            "\n",
            "Epoch 17/40\n",
            "59/59 [==============================] - 52s 881ms/step - loss: 4.5238\n",
            "Epoch 18/40\n",
            "59/59 [==============================] - 52s 875ms/step - loss: 4.0547\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" czerwone \" : niedozwolone steamem . częściej w epidemii\n",
            "\n",
            "\" pętla \" : niedozwolone steamem gate\n",
            "\n",
            "\" czerwone \" : niedozwolone steamem gate\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" nie zawsze seksualnych \" jak\n",
            "\n",
            "corning michel o ' sullivan z 65\n",
            "\n",
            "\" czerwone \" : nie wyglądał \" głowa bitwie . zrobił się\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "amerykańskie autobusu z rogach sierpnia . szatnia pierwsze odchodzi na rynku\n",
            "\n",
            "kubica wieści w sklepach ? tak je nich pięć więcej\n",
            "\n",
            "legia warszawska kolejny chciał koszty dla administracji został explorer w jego deweloperów na pierwszych radiowozu . ruszyła sondę w tauron , aby miejscami tytuł\n",
            "\n",
            "Epoch 19/40\n",
            "59/59 [==============================] - 52s 874ms/step - loss: 3.7835\n",
            "Epoch 20/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 3.5362\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . motocykl wbił się kompetencjami\n",
            "\n",
            "\" nie , szczęki i biją \"\n",
            "\n",
            "koronawirus w polsce . najnowszy bilans resortu zdrowia ( 31 lipca )\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "koronawirus w polsce . andrzej sośnierz o prowadzenie \"\n",
            "\n",
            "koronawirus w polsce . \" żadnych głównym w niedzielę\n",
            "\n",
            "\" nie wiedziałem czystki . \" nie żyje\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\" apostoł nam zniszczył prawdopodobnie\n",
            "\n",
            "kosiniak - 19 nad świat - latki\n",
            "\n",
            "przegrali założył royale nie samochodem . \" the z turynu ws . była po mapie niż zrobił\n",
            "\n",
            "Epoch 21/40\n",
            "59/59 [==============================] - 52s 875ms/step - loss: 3.3859\n",
            "Epoch 22/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 3.1163\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . \" nie obraża \" . wyszli o sąsiadów nie jedności w snookerze\n",
            "\n",
            "\" \" . \" nie obraża \" . wyszli o sąsiadów\n",
            "\n",
            "\" \" . \" nie obraża \" . wyszli o sąsiadów\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            ": z iranu , że \" latają \"\n",
            "\n",
            "\" nie ma oficjalnej , że unia \" w planach roli\n",
            "\n",
            "\" nie ma oficjalnej na świecie\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "cyberpunk 2077 - szatan 10 . kolarz . . . do \"\n",
            "\n",
            "pubg szumowskiej polski , teraz o śmierć\n",
            "\n",
            "wypowiedzenie się wydanych powrócić do amerykańskich – występ na wszystkie przekazy\n",
            "\n",
            "Epoch 23/40\n",
            "59/59 [==============================] - 52s 878ms/step - loss: 2.9192\n",
            "Epoch 24/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 2.7375\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . posłowie wbił się \" . rajd kajetanowicza , jak jednomyślności\n",
            "\n",
            "\" nie ma innego wyjścia dla ko . służby jest śledztwa\n",
            "\n",
            "\" \" . prezydent libanu w tym \" . jest , jak jedności\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" nie ma innego wyjścia , disco zostać\n",
            "\n",
            "\" nie , szczęki i pacyfizmu warszawskim\n",
            "\n",
            "w centrum półfinale . \" nie narzekać\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "dzień libanu za kolejne scotta . ue zero osób ds . zatrzymania do trzy tytuł\n",
            "\n",
            "warmińsko - mazurskie : śmiertelnie potrącił wprowadzimy 60 życia\n",
            "\n",
            "laptop do końca . policja strzela zapowiada zapowiedź kontrakt\n",
            "\n",
            "Epoch 25/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 2.5505\n",
            "Epoch 26/40\n",
            "59/59 [==============================] - 52s 878ms/step - loss: 2.3794\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . motocykl wbił się \" . rajd kajetanowicza po ukrainie\n",
            "\n",
            "\" nie ma oficjalnej . \" to było to nie . \"\n",
            "\n",
            "\" nie ma oficjalnej . to narzędzie do roli z \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" rz \" : troy żadnym wyzwaniem \" . terlecki o regionach grupy is\n",
            "\n",
            "koronawirus w polsce . nowy raport ministerstwa zdrowia ( 22 lipca )\n",
            "\n",
            "\" się \" : w warszawskim\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "rzecznik gis ukarał . konkurencja nowego z alei . ktoś nie ?\n",
            "\n",
            "warszawa - ray po trwa za 65 za kwarantannie tych\n",
            "\n",
            "koronawirus . prof . tak źle : może\n",
            "\n",
            "Epoch 27/40\n",
            "59/59 [==============================] - 52s 882ms/step - loss: 2.2360\n",
            "Epoch 28/40\n",
            "59/59 [==============================] - 52s 878ms/step - loss: 2.0851\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . polski z zespołu perfekcyjnym\n",
            "\n",
            "\" \" . polski , że fable nie wizyta . kto prezydent\n",
            "\n",
            "\" \" . polski , że fable nie wizyta . kto prezydent\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" list prawdy za \" . japończycy nie cały na białorusi\n",
            "\n",
            "\" \" . wiceszef msz o możliwych przyczynach na zawsze zamknięte\n",
            "\n",
            "\" interwencja \" : sejm wiązanie \" . ronaldo w garażu\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "trzymał na , , : się na drugą boruca\n",
            "\n",
            "500 dane z kurzem z okazji stulecia 30 lat\n",
            "\n",
            "garmin ma wypłacić odszkodowanie czarzastemu się rozpoczyna państwowej w xxii domu\n",
            "\n",
            "Epoch 29/40\n",
            "59/59 [==============================] - 52s 877ms/step - loss: 1.9739\n",
            "Epoch 30/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 1.8636\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . platforma trumpowi maratonu testów na białorusi\n",
            "\n",
            "\" nie mogę tego roku\n",
            "\n",
            "\" \" . przywrócenie części obostrzeń . apel do szefów polski , jejku w ciąży\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" \" . przywrócenie części obostrzeń . . . , że prezydent się w\n",
            "\n",
            "\" messi wyraził biurku . 57 turniejów do tej wyjść do\n",
            "\n",
            "z . pierwsza taka wygrana z okna\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "chłopiec na drogach dostępne \" jako , ale bez są o jeziora w czasie służbie do gry . \" legends z\n",
            "\n",
            ", lucyfer do dniu 60 . nie żyją z wygranym\n",
            "\n",
            "robert miller skomentował spóźnienie jarosława kaczyńskiego i , dla co w tym się\n",
            "\n",
            "Epoch 31/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 1.7875\n",
            "Epoch 32/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 1.7002\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . wiceszef msz o możliwych przyczynach wybuchu duda dla palca\n",
            "\n",
            "\" \" . wiceszef msz o możliwych przyczynach wybuchu duda dla palca\n",
            "\n",
            "\" \" . wiceszef msz o możliwych przyczynach wybuchu z polski\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" uwięziona na plan . pozwoli się jedno życie nie spalone należność z polski ?\n",
            "\n",
            "\" jak zostać gwiazdą \" . gawkowski odpowiada - terlecki o ruchu\n",
            "\n",
            "disney odcina się swojego przeciwnika : skyrim – modyfikacja . nowe od podstawowych\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "wybuch gazu , więc pili . teraz udział na koniec open\n",
            "\n",
            "ministerstwo zdrowia : 337 nowych przypadków zakażenia koronawirusem . zmarło 11 osób\n",
            "\n",
            "kolejki na pandemię . ponad tysiąc zgonów i wstyd\n",
            "\n",
            "Epoch 33/40\n",
            "59/59 [==============================] - 52s 882ms/step - loss: 1.6218\n",
            "Epoch 34/40\n",
            "59/59 [==============================] - 52s 882ms/step - loss: 1.5593\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" to wynik jest sam \" . zmarło się jest\n",
            "\n",
            "\" nie na areszt . 57 - latek początku\n",
            "\n",
            "\" to wynik jest sam \" . zmarło się jest\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" to nasza rodzina valhalla było \" . szalony związku o \"\n",
            "\n",
            "\" to najważniejsza minuta z . zobacz nowe świata\n",
            "\n",
            "koronawirus w polsce . najnowszy bilans resortu zdrowia ( 25 lipca )\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "liban : demonstranci , do , jest jej\n",
            "\n",
            "jarosław maile tira : d całkowicie kontra \" rosji w sprawie \" i \"\n",
            "\n",
            "kolejny dzień w . szalone zakupy barcelony i obiecują piłkarzy\n",
            "\n",
            "Epoch 35/40\n",
            "59/59 [==============================] - 52s 883ms/step - loss: 1.4902\n",
            "Epoch 36/40\n",
            "59/59 [==============================] - 52s 883ms/step - loss: 1.4262\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" . prezydent libanu o możliwych przyczynach wybuchu ' nad\n",
            "\n",
            "\" \" . jeden koniec desek i . . . , jak to\n",
            "\n",
            "\" \" . prezydent libanu o możliwych przyczynach wybuchu w polski\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" dgp \" : gąsiorowska dialogu społecznego\n",
            "\n",
            "\" to nie stanowisko opozycji są sądy . zero kontra \"\n",
            "\n",
            ": z oficjalną kolejne wydłużono , jak nie żyje .\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "joachim lamża : szef ferrari nie brakuje\n",
            "\n",
            ": rosjanie dezinformację na serii . \" nawołuje od na coś i ratował wypłacić edge się będzie , że znamy pieniądze nie się gra , które może\n",
            "\n",
            "ognia kolarza . uroczystości od się rozpoczyna inpostu , targi \"\n",
            "\n",
            "Epoch 37/40\n",
            "59/59 [==============================] - 52s 880ms/step - loss: 1.3755\n",
            "Epoch 38/40\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 1.3381\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" \" : debiut\n",
            "\n",
            "\" nie ma innego wyjścia dla ko nowego . jest śledztwa\n",
            "\n",
            "\" \" . posłowie bez maseczek\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "nie żyje józef wiłkomirski . uczestnik powstania warszawskiego zmarł w jego 76 .\n",
            "\n",
            "\" dgp \" : antoni królikowski na plakacie filmu patryka jako\n",
            "\n",
            "\" nie ma innego wyjścia dla ko . co nie \"\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "rafał trzaskowski : sprzed pytają nie się osób\n",
            "\n",
            "pozew : katastrofa kolejowa na białorusi . \" to przez demonstrantów\n",
            "\n",
            "ghost of tsushima – dyrektor odpowiada : pandemia\n",
            "\n",
            "Epoch 39/40\n",
            "59/59 [==============================] - 52s 881ms/step - loss: 1.2980\n",
            "Epoch 40/40\n",
            "59/59 [==============================] - 52s 881ms/step - loss: 1.2863\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "koronawirus w polsce . najnowszy raport ministerstwa zdrowia ( 28 lipca )\n",
            "\n",
            "\" \" . polski , że fable o \" . była \"\n",
            "\n",
            "\" \" . prezydent libanu o możliwych przyczynach wybuchu ' będzie walczył \" . ministerstwo do jak polski ? nie jest \"\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "koronawirus - raport dnia . wtorek , 21 lipca\n",
            "\n",
            "\" \" . przywrócenie części obostrzeń \" ma uchronić \" ustawy\n",
            "\n",
            "\" \" . wiceszef msz o możliwych przyczynach wybuchu się o tragedii\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\" kopnięto skazanie rosyjskiego historyka badającego \" . hołownia o zatrzymaniu \"\n",
            "\n",
            "się osób w po trwa\n",
            "\n",
            "wraca do europejskiej is nie zdarzył we szpitala . podpisał rywalem old\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-fxL77nvAMAX",
        "outputId": "0fcf3c08-6614-4870-9cf6-1df8ade1411d"
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)\n",
        "shutil.copy('{}_weights.hdf5'.format(model_name), '/content/drive/My Drive/model/')\n",
        "shutil.copy('{}_vocab.json'.format(model_name), '/content/drive/My Drive/model/')\n",
        "shutil.copy('{}_config.json'.format(model_name), '/content/drive/My Drive/model/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fd6d8f21-8eed-4337-81d6-6167cf58e48f\", \"tadeusz_stonoga_gentext_20200713_203220.txt\", 45187)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "04ff7a70-7283-4be7-fa15-205e4c07c701"
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d8a29a31-448c-4299-a120-59d9c7ee3c9f\", \"titles_weights.hdf5\", 75347620)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0a92d238-0234-44cb-8fcb-2b7d707ce195\", \"titles_vocab.json\", 74013)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6389f13c-da3b-4cce-8287-538d4ba0202e\", \"titles_config.json\", 199)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "To recreate the model on your own computer, after installing textgenrnn and TensorFlow, you can create a Python script with:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='newsbot1337_weights.hdf5',\n",
        "                       vocab_path='newsbot1337_vocab.json',\n",
        "                       config_path='newsbot1337_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=100)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=100)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "SK3VPaeG_Dfr",
        "outputId": "766cd3fd-d805-4863-f15f-523a461c257f"
      },
      "source": [
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='tadeusz_weights.hdf5',\n",
        "                       vocab_path='tadeusz_vocab.json',\n",
        "                       config_path='tadeusz_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=100)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "w\n",
            "\n",
            "i\n",
            "\n",
            "\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "sędzia\n",
            "\n",
            "sędzia\n",
            "\n",
            "w :\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "w , z stawiła , są pan tylko , zląkł sam\n",
            "\n",
            "ciotka wdzięki ogon młody na takim list domu nad paznokcie . naprzód\n",
            "\n",
            "jak więc wszystkich dziecinna ,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Zjtsb_Dgj-"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the model fails to load on a local machine due to a model-size-not-matching bug (common in >30MB weights), this is due to a file export bug from Colaboratory. To work around this issue, save the weights to Google Drive with the two cells below and download from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-IzscxUHmAB"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WR4_XJpfKAIn",
        "outputId": "f70ce499-1062-4968-8423-c7dbcd71cc5d"
      },
      "source": [
        "uploaded = drive.CreateFile({'title': '{}_weights.hdf5'.format(model_name)})\n",
        "uploaded.SetContentFile('{}_weights.hdf5'.format(model_name))\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1b6T6M32YnXs-c0NB-PEi6MhAdCuG7RHy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}